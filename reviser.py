import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser
from prompts import revision_prompt

# Initialize the LLM with your Google Gemini API key
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    google_api_key=os.getenv("GEMINI_API")
)

# Output parser to get string output from the LLM
parser = StrOutputParser()

# Create a chain by piping the prompt into the LLM and then into the parser
chain = revision_prompt | llm | parser

def revise_document(original: str, feedback: str) -> str:
    """
    Uses the LLM chain to revise the original document content based on the feedback.
    
    Args:
        original (str): The original document content.
        feedback (str): The revision feedback or instructions.
    
    Returns:
        str: The revised document content generated by the LLM.
    """
    # Call the chain with inputs as a dictionary and return the revised content string
    return chain.invoke({
        "original_content": original,
        "feedback": feedback
    })
